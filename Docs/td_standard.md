针对使用 Cursor 进行较大项目开发的测试与 Debug 规范

下面的规范旨在帮助开发者在使用 Cursor 辅助开发较大型项目时，建立完善的测试体系并采用高效的调试策略。通过遵循这些准则，可以最大程度减少 AI 生成的"幻觉"代码对项目的影响，并确保项目质量和开发效率。

1. 测试体系
	•	测试框架层次：建立完整的测试框架，包括单元测试、功能测试、集成测试和端到端 (E2E) 测试。其中，集成测试需涵盖分阶段的模块集成测试和整体系统级的集成测试，确保各模块既能各自正常运行，也能在一起协同工作。E2E 测试则从用户或系统交互的角度，验证整个应用流程的正确性。
	•	测试执行顺序：严格遵循测试执行的顺序和流程：先运行单元测试 -> 然后功能测试 -> 接着集成测试（先局部后整体）-> 最后端到端测试。只有当前一层级的测试全部通过后，才能进入下一层级测试，以确保问题能够在尽可能早的阶段被发现并解决。
	•	新功能测试要求：任何新增的功能或模块必须编写相应的测试用例予以覆盖。提交新代码时，应同时提交新的或更新的测试，确保新功能行为符合预期并且不会破坏现有功能。
	•	禁止随意修改已通过的测试：已通过的测试用例代表既定的需求和正确行为，不可为了让代码通过而随意修改这些测试。若确实由于需求变更需要调整测试，应在评审后有计划地进行，防止误将代码缺陷当作测试错误来处理。
	•	测试用例规范：所有编写或生成的测试用例应符合项目定义的测试标准（详见 @test_standard.md）。这意味着测试的命名、结构、断言风格等都应满足标准要求，以保持测试代码的可读性和一致性。

2. 防止 Cursor 生成幻觉代码
	•	提供项目上下文：在让 Cursor 生成代码之前，先让其读取当前项目的结构和已有内容。可以通过提供项目的文件树、已有模块列表或关键代码片段的方式，为 Cursor 提供准确的上下文。这有助于避免 AI 对项目结构的误解，防止其凭空臆造不存在的文件或函数。
	•	验证模块引用：要求 Cursor 在每次生成代码前检查其要导入的模块是否真实存在于项目代码库或依赖库中。如果 Cursor 提出导入一个不存在的模块，必须让其解释该模块的来源和目的——例如，它是标准库模块、第三方库（需要添加依赖），还是意图创建的新内部模块。在继续之前，对此进行审查和确认，避免引入不存在的依赖。
	•	受控的文件创建：禁止 Cursor 擅自创建新文件或新模块来绕过测试失败。任何新增文件或模块都应事先经过批准和设计，而不应由 AI 自行决定。换言之，当测试未通过时，应让 Cursor 着重修复现有代码中的问题，而非通过引入额外的模块作为权宜之计。如果确实需要新增文件，也应先讨论其必要性，评估对项目结构的影响，并得到明确授权后再生成。

3. 高效 Debug 策略
	•	遵循调试规范：调试过程应严格遵守项目的调试标准和流程（详见 @debug_standard.md）。遵循既定的调试指南有助于保持问题诊断和修复的一致性，确保 Cursor 的调试行为在可控范围内，例如：如何记录 Bug、如何定位问题根因、如何验证修复等都应有章可循。
	•	小步迭代调试：采用小步调试（逐步调试）的方式来解决问题。每次只定位和修复一个 Bug，然后立即运行相关的测试用例验证修复是否成功。只有当这个 Bug 修复确认无误后，再着手处理下一个问题。这样可以将问题各个击破，避免一次性修改过多导致难以定位新引入的错误。
	•	附加修改原因：对于每一次代码修改，都要附带修改原因的说明。这可以通过在提交日志、代码评审备注或代码注释中阐明：修改的动机是什么，解决了哪个问题，以及为什么以这种方式解决。要求 Cursor 在生成修复代码时也输出简要的原因说明。这种做法有助于审查，更重要的是防止 AI 在没有明确理由的情况下大范围修改代码。始终聚焦于最小必要的改动，减少牵一发而动全身式的连锁问题。
	•	使用调试分支：建立一个专门的Debug 分支来进行调试工作和 Bug 修复。所有修复在该分支上进行测试和验证，确认稳定后再合并回主分支。这样可以确保主分支始终保持相对稳定，同时调试过程和每次修改都有迹可循。如果某次调试修改导致新的问题，可以方便地回退或比较差异，保证调试过程的可追溯性和安全性。

4. 环境校验
	•	依赖完整性检查：确保项目的前端和后端依赖文件（例如 requirements.txt、package.json 或类似配置）中包含了所有代码运行所需的模块和库。在 Cursor 生成代码前或后，都应该进行依赖校验：如果 AI 引入了新的第三方库，需要先将该库添加到依赖清单并安装，再运行测试。定期更新和审核依赖文件，防止遗漏，确保项目在任何环境下都能一键安装运行。
	•	遵守 Cursor 规则：在 Cursor 生成代码时，检查项目根目录下是否有 .cursorrules 文件，并遵守其中定义的规则。该文件可能包含对 AI 代码生成的约束（如禁止重复某些模块、规定代码风格或模块划分等）。通过预先加载 .cursorrules 的内容给 Cursor，确保其了解既定约定，避免生成与现有模块功能重复或违反项目规范的代码。例如，如果 .cursorrules 指定某功能应在特定模块实现，就应避免 Cursor 在其他地方重新实现相似功能。

5. 数据获取测试规范
	•	数据获取必须可靠：针对与数据获取相关的功能（如财务数据、股票行情、资金流向等），严禁因获取不到数据而简单地跳过（skip）相关测试。这些核心业务功能的测试失败应视为严重问题，必须解决而非回避。
	•	API 文档驱动开发：在实现和测试数据获取功能时，必须充分参考相关 API 文档（如 akshare.md），确保正确理解 API 的参数要求、返回格式和使用限制。遇到数据获取问题时，应先查阅文档，理解 API 行为，再针对性解决问题。
	•	多数据源策略：对于关键业务数据，必须实现多数据源获取策略。当主要数据源无法获取数据时，应自动尝试备用数据源。例如，财务数据既可从新浪财经获取，也可从东方财富获取；行情数据可从多个行情提供商获取。在测试中，应验证这种容错机制的有效性。
	•	模拟响应要精确：编写测试时，模拟的 API 响应必须精确反映真实 API 的返回结构，包括列名、数据类型和可能的特殊值（如 null、NaN 等）。不准确的模拟会导致测试通过但实际代码失败的情况。
	•	异常处理测试：必须专门测试数据获取过程中的各类异常情况，包括但不限于：网络超时、API 限流、返回格式变化、数据缺失等。这些测试应验证系统是否能正确处理异常并采取适当的恢复措施。
	•	实现重试机制：数据获取功能必须实现智能重试机制，包括指数退避策略和最大重试次数限制。测试应验证此机制在各种失败情况下的表现。
	•	数据一致性校验：获取的数据必须经过一致性校验，确保满足预期的业务规则（如资产=负债+所有者权益，成交量与成交额关系合理等）。测试应覆盖这些校验规则。
	•	增量更新测试：对于支持增量更新的数据（如日线行情、财务报表），必须测试增量更新功能的正确性，确保不会重复获取已有数据，也不会遗漏新数据。
	•	正确处理中文特殊单位转换：金融数据中常见的"亿"、"万"等中文单位需要正确转换为标准数值。测试应验证单位转换的准确性，确保存入数据库的是正确的数值大小。
	•	数据来源追踪：所有获取的数据都应有明确的来源标记，便于追溯和验证。测试应确保数据来源信息被正确记录。
	•	完善的API路径模拟：在测试中模拟外部API时，必须确保模拟的是代码中实际使用的API路径。例如，对于类似`import akshare as ak`的导入方式，应模拟`backend.data.collectors.module.ak.function`而非直接模拟`akshare.function`。
	•	参数传递验证：测试应验证过滤参数（如日期范围）是否正确传递给底层API。尤其是多层API调用的情况下，需确保参数在各层间的正确传递。
	•	执行端到端验证：数据收集器的测试不应限于单元级别，还应包括从API调用到数据存储的完整流程测试，验证整个管道的有效性。
	•	多数据源策略测试：对于实现了多数据源策略的收集器，必须测试所有可能的数据源路径，包括主要数据源成功、主要数据源失败但备用数据源成功、以及所有数据源都失败的情况。确保在任何情况下都能得到预期的行为（成功获取数据或返回空集合）。
	•	股票代码格式处理测试：针对不同市场（上海、深圳、科创板、创业板等）的股票，测试收集器是否能正确处理不同格式的股票代码（纯数字、带市场后缀、带市场前缀等）。这对于使用多个API的收集器尤为重要，因为不同API可能要求不同的股票代码格式。
	•	中文日期格式处理测试：测试收集器是否能正确解析和标准化各种中文日期格式（如"2023年12月31日"）。确保日期格式化逻辑在各种情况下都能正确工作。
	•	列名映射测试：测试收集器是否能正确识别和映射不同API返回的各种列名（如"净资产收益率"、"ROE"、"净资产收益率(%)"等）到标准化的内部字段名。这对于处理多个数据源尤为重要，因为不同数据源可能使用不同的命名约定。
	•	错误处理流程测试：测试收集器在遇到各种错误情况时的行为，包括API连接错误、认证错误、格式错误等。确保错误被正确记录，且不会阻止尝试备用数据源。
	•	数据一致性跨源验证：当从多个数据源获取相同数据时，测试收集器是否能正确处理可能存在的数据不一致问题，例如通过优先级规则或数据合并策略。

6. 调试方法论
	• 结构化问题识别：发现问题后，应遵循结构化的报告格式进行记录和沟通。问题报告应包含：(1)问题现象的清晰描述；(2)复现步骤；(3)期望行为与实际行为的对比；(4)相关的错误日志或输出。这种结构化的问题描述有助于其他开发者快速了解问题，并防止遗漏关键信息。
	• 根本原因分析：调试时注重寻找问题的根本原因，而非仅关注表面现象。应采用系统性的分析方法，如"五个为什么"技术，层层深入直至找到最根本的原因。分析应基于证据（如日志、数据流分析、代码审查），避免凭直觉或假设得出结论。在提出修复方案前，必须确认已理解真正的根因。
	• 解决方案提案：针对发现的问题，提出的解决方案应包括：(1)修复措施的详细说明；(2)修复原理，即为何这样修复能解决问题；(3)潜在的影响范围，特别是可能波及的其他功能；(4)验证方案，即如何确认修复的有效性。完整的解决方案提案有助于评审和实施，防止引入新问题。
	• 核心逻辑优先：调试过程中，始终优先关注核心业务逻辑和关键功能，而非单纯为了通过测试而修改代码。理解核心逻辑的正确性是第一位的，测试应视为验证手段而非目的。避免通过修改测试或添加特例代码来掩盖实际问题。正确的解决顺序是：先修复核心逻辑错误，再确保测试正确反映期望行为，最后验证测试通过。
	• 目录结构规范：创建测试文件和调试脚本时，必须遵循项目的目录结构规范。单元测试应放在对应模块的test目录下，集成测试位于集成测试专用目录，调试脚本也应有明确的存放位置。临时调试文件应标记为临时，并在调试完成后移除或重构为正式测试。严禁在项目根目录或随机位置创建测试文件，以保持项目结构的清晰和一致。
	• 自顶向下的理解：接手调试任务时，应先从宏观角度理解整个模块或系统的设计和数据流，然后再深入具体的函数或代码行。这意味着首先阅读模块的主要类和接口定义，了解关键数据结构和核心流程，再逐步深入到可能出问题的具体实现细节。这种"自顶向下"的方法能够获得更全面的问题视角，避免陷入片面的局部优化。
	• 增量式调试：采用小步骤、增量式的调试方法。每次只调整一个变量或修复一个问题，然后验证效果，再进行下一步。这种方法可以清晰地看到每个更改的影响，便于定位问题。调试过程应保持日志记录，记录尝试过的方法、观察到的结果和得出的结论，形成完整的调试线索，便于后续回顾和分享经验。
	• 构建专用调试工具：对于复杂或难以重现的问题，应创建专用的调试工具或脚本。这些工具应能够:(1)模拟真实环境下的数据流和交互；(2)提供更详细的日志和中间状态信息；(3)支持问题的快速复现和验证。精心设计的调试工具能极大提高问题诊断的效率和准确性。调试工具本身也应保持良好的代码质量和文档，以便日后重用。
	• 综合验证策略：修复问题后，应采用多层次的验证策略确认修复的完整性：单元测试验证局部功能，集成测试验证与其他模块的协同，端到端测试验证用户场景的完整流程，性能测试确保没有引入性能退化。对于数据相关的修复，尤应验证各种边界条件和特殊情况（如空值、极端值、错误格式等）。只有通过全面验证的修复才能被视为完成。
	• 文档化经验教训：每次重大问题的调试和修复过程都应记录为经验教训文档。文档应总结问题的本质、发现过程、解决方法以及预防类似问题的建议。这些经验教训应在团队内共享，并反映到对应的最佳实践指南中，形成不断完善的技术知识库，提升整个团队的开发水平和代码质量。  
	• 明确调试阶段：将调试过程明确划分为几个阶段:(1)问题复现—确认能够稳定重现问题；(2)问题隔离—缩小问题范围，定位到具体模块或函数；(3)根因分析—找出导致问题的根本原因；(4)方案设计—设计修复方案；(5)实施修复—编码实现解决方案；(6)验证修复—全面测试确认问题已解决且无副作用。每个阶段都有明确的输入、活动和输出，这种阶段性划分有助于系统化调试流程，防止盲目尝试或跳过关键步骤。

7. CI/CD 考虑（可选）
	•	提前布局自动化流程：尽管当前属于个人开发阶段，但应为未来引入持续集成/持续部署（CI/CD）做好准备。可以在项目中保持良好的测试组织结构，并编写CI配置（例如GitHub Actions或GitLab CI配置文件），以便日后无缝接入自动化测试流程。一旦引入 CI/CD，每次代码变更都将触发自动化测试（包括单元、集成和E2E测试），及时发现回归问题，保障代码库的健康。
	•	确保规范适用于 CI：当前制定的测试与调试规范将为将来的 CI/CD 奠定基础。通过严格的测试顺序和全面的用例覆盖，CI 环境下的测试才能可靠地通过。调试分支的做法也便于在CI流程中进行分支构建和测试。总之，提前养成这些良好习惯，可使项目日后平稳过渡到自动化测试与部署，提高开发效率和代码质量。